# AI Multimodal Timeline

Here we will track the latest AI Multimodal Models, including Multimodal Foundation Model, LLM, Audio, Image, Video, Music and 3D content. üî•

## Table of Contents

* [Multimodal Model](#multimodal)
* [LLM](#llm)
* [Audio](#audio)
* [Image](#image)
* [Video](#video)
* [Music](#music)
* [3D](#3d)



## Project List

###  <span id="multimodal">Multimodal Model</span>

| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------- | :-----------: | :-------: |
|    2024-05    | [Groma](https://github.com/FoundationVision/Groma)                      | Grounded Multimodal Large Language Model with Localized Visual Tokenization.            |[arXiv](https://arxiv.org/abs/2404.13013)  |[Hugging Face](https://huggingface.co/FoundationVision/groma-7b-finetune)  |
|    2024-05    | [CogVLM2](https://github.com/THUDM/CogVLM2)                      | GPT4V-level open-source multi-modal model based on Llama3-8B.            |                                                               |[Hugging Face](https://huggingface.co/THUDM/cogvlm2-llama3-chat-19B)  |
|    2024-05    | Chameleon                | Mixed-Modal Early-Fusion Foundation Models.            |[arXiv](https://arxiv.org/abs/2405.09818)  |                                                 |
|    2024-05    | [Lumina-T2X](https://github.com/Alpha-VLLM/Lumina-T2X)                | Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers.            |[arXiv](https://arxiv.org/abs/2405.05945)  |[Hugging Face](https://huggingface.co/Alpha-VLLM/Lumina-Next-T2I)  |
|    2024-05    | [MiniCPM-Llama3-V 2.5](https://github.com/OpenBMB/MiniCPM-V)                | MiniCPM-Llama3-V 2.5 is the latest model in the MiniCPM-V series. The model is built on SigLip-400M and Llama3-8B-Instruct with a total of 8B parameters.            |                                     |[Hugging Face](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5)  |
|    2024-05    | [Gemini](https://deepmind.google/technologies/gemini/)                      | Build with state-of-the-art generative models and tools to make AI helpful for everyone.            |                                                               |[API](https://ai.google.dev/)  |
|    2024-05    | [GPT-4o](https://openai.com/index/hello-gpt-4o/)                            | GPT-4o (‚Äúo‚Äù for ‚Äúomni‚Äù) is a step towards much more natural human-computer interaction‚Äîit accepts as input any combination of text, audio, image, and video and generates any combination of text, audio, and image outputs.            |                                                               |[API](https://platform.openai.com/docs/models/gpt-4o)  |
|    2023-05    | [ImageBind](https://github.com/facebookresearch/ImageBind)                | One Embedding Space To Bind Them All.            |[arXiv](https://arxiv.org/abs/2305.05665)  |[Website](https://imagebind.metademolab.com/)  |

<p style="text-align: right;"><a href="#table-of-contents">^ Back to Contents ^</a></p>


###  <span id="llm">LLM</span>

| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :-----------: | :-------: |
|    2024-04    | [Llama 3](https://github.com/meta-llama/llama3)                | Meta Llama 3 is the next generation of our state-of-the-art open source large language model.            |                                     |[Hugging Face](https://huggingface.co/meta-llama)  |
|    2024-03    | [Claude 3](https://www.anthropic.com/claude)                   | Talk with Claude, an AI assistant from Anthropic.            |                                                               |[API](https://www.anthropic.com/api)  |
|    2023-09    | [Baichuan 2](https://github.com/baichuan-inc/Baichuan2)        | A series of large language models developed by Baichuan Intelligent Technology.            |                                     |[Hugging Face](https://huggingface.co/baichuan-inc)  |
|    2023-07    | [GPT-4](https://openai.com/index/gpt-4/)                                    | GPT-4 is OpenAI‚Äôs most advanced system, producing safer and more useful responses.            |                                                               |[API](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4)  |

<p style="text-align: right;"><a href="#table-of-contents">^ Back to Contents ^</a></p>


###  <span id="audio">Audio</span>
#### Audio/Text-to-Speech
| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :-----------: | :-------: |
|    2024-05    | [ChatTTS](https://github.com/2noise/ChatTTS)                     | ChatTTS is a text-to-speech model designed specifically for dialogue scenario such as LLM assistant.            |  | |
|    2023-06    | [StyleTTS 2](https://github.com/yl4579/StyleTTS2)                | Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models.            |[arXiv](https://arxiv.org/abs/2306.07691)  |[Hugging Face](https://huggingface.co/spaces/styletts2/styletts2)  |

#### Audio/Automatic Speech Recognition
| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :-----------: | :-------: |
|    2024-05    | [TeleSpeech-ASR](https://github.com/Tele-AI/TeleSpeech-ASR)                | Large speech model-super multi-dialect ASR.            |      |[Hugging Face](https://huggingface.co/Tele-AI/TeleSpeech-ASR1.0)  |
|    2022-12    | [Whisper](https://github.com/openai/whisper)                | Whisper is a general-purpose speech recognition model.            |[arXiv](https://arxiv.org/abs/2212.04356)  |[API](https://platform.openai.com/docs/models/whisper)  |

<p style="text-align: right;"><a href="#table-of-contents">^ Back to Contents ^</a></p>


###  <span id="image">Image</span>

| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :-----------: | :-------: |
|    2024-05    | [Hunyuan-DiT](https://github.com/Tencent/HunyuanDiT)                | A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding.            |[arXiv](https://arxiv.org/abs/2405.08748)  |[Hugging Face](https://huggingface.co/Tencent-Hunyuan/HunyuanDiT)  |
|    2023-10    | [DALL¬∑E 3](https://openai.com/index/dall-e-3/)                      | DALL¬∑E is a AI system that can create realistic images and art from a description in natural language.            |     |[API](https://platform.openai.com/docs/models/dall-e)  |

<p style="text-align: right;"><a href="#table-of-contents">^ Back to Contents ^</a></p>


###  <span id="video">Video</span>

| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :-----------: | :-------: |
|    2024-05    | [Vidu](https://www.vidu.io/)                                              | Vidu: a Highly Consistent, Dynamic and Skilled Text-to-Video Generator with Diffusion Models.            |[arXiv](https://arxiv.org/abs/2405.04233)  |                             |
|    2024-02    | [Sora](https://openai.com/index/sora/)                                    | Sora is an AI model that can create realistic and imaginative scenes from text instructions.            |[Technical Report](https://openai.com/index/video-generation-models-as-world-simulators/)  |                             |
|    2023-11    | [Pika](https://pika.art/home)                                             | Pika is the idea-to-video platform that sets your creativity in motion.            |     |                             |
|    2023-03    | [Runway](https://runwayml.com/)                                           | Runway is an applied AI research company shaping the next era of art, entertainment and human creativity.            |     |                             |

<p style="text-align: right;"><a href="#table-of-contents">^ Back to Contents ^</a></p>


###  <span id="music">Music</span>

| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :-----------: | :-------: |
|    2024-04    | [Udio](https://www.udio.com/)                | Udio - AI Music Generator                |                                                                                      |[Website](https://www.udio.com/)  |
|    2023-12    | [Suno](https://suno.com/)                | Suno is building a future where anyone can make great music.            |                                                                                      |[Website](https://suno.com/)  |

<p style="text-align: right;"><a href="#table-of-contents">^ Back to Contents ^</a></p>


###  <span id="3d">3D</span>

| Date          | Source                   | Description                                                 |   Paper   |  Model  |
| :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- | :-----------: | :-------: |
|    2024-03    | [TripoSR](https://github.com/VAST-AI-Research/TripoSR)                | Fast 3D Object Reconstruction from a Single Image.            |[arXiv](https://arxiv.org/abs/2403.02151)  |[Hugging Face](https://huggingface.co/spaces/stabilityai/TripoSR)  |

<p style="text-align: right;"><a href="#table-of-contents">^ Back to Contents ^</a></p>



